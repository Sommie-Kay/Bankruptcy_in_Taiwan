{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ebb9e36-124b-4cc1-a250-709e6ba98b58",
   "metadata": {},
   "source": [
    "# Predicting Bankruptcy in Taiwan Using Gradient Boosting Trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247cc655-2952-4572-b8b7-4bd8807c442a",
   "metadata": {},
   "source": [
    "In the previous notebook, I used an ensemble model named random forest to extend the analysis done  with the decision tree and  saw that the random forest model performed better .Now I'll be considering another type of ensemble model called the gradient boosting tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8118f736-a10d-4b4c-a956-0a1c911ba271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from ipywidgets import interact\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from teaching_tools.widgets import ConfusionMatrixWidget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c2500-ac26-49d8-8c24-4f3db5a9da9a",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126f47d4-01ed-4b89-b66e-2e4ae5fdd253",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710676ca-c39d-4e8b-984d-bd1d9dc1a0a1",
   "metadata": {},
   "source": [
    "I'll import the wrangle function I created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4822824-4720-49ef-bc1d-6dc56323dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our wrangle function created in the previous notebook\n",
    "def wrangle(filename):\n",
    "    # open compressed file,load into dict\n",
    "    with gzip.open(filename,\"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # turn dict into dataframe\n",
    "    df = pd.DataFrame().from_dict(data[\"observations\"]).set_index(\"id\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8225f79-479d-4291-888a-0d008e81fbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (6137, 96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bankrupt</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>feat_94</th>\n",
       "      <th>feat_95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bankrupt    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n",
       "id                                                                         \n",
       "1       True  0.370594  0.424389  0.405750  0.601457  0.601457  0.998969   \n",
       "2       True  0.464291  0.538214  0.516730  0.610235  0.610235  0.998946   \n",
       "3       True  0.426071  0.499019  0.472295  0.601450  0.601364  0.998857   \n",
       "4       True  0.399844  0.451265  0.457733  0.583541  0.583541  0.998700   \n",
       "5       True  0.465022  0.538432  0.522298  0.598783  0.598783  0.998973   \n",
       "\n",
       "      feat_7    feat_8    feat_9  ...   feat_86   feat_87   feat_88   feat_89  \\\n",
       "id                                ...                                           \n",
       "1   0.796887  0.808809  0.302646  ...  0.716845  0.009219  0.622879  0.601453   \n",
       "2   0.797380  0.809301  0.303556  ...  0.795297  0.008323  0.623652  0.610237   \n",
       "3   0.796403  0.808388  0.302035  ...  0.774670  0.040003  0.623841  0.601449   \n",
       "4   0.796967  0.808966  0.303350  ...  0.739555  0.003252  0.622929  0.583538   \n",
       "5   0.797366  0.809304  0.303475  ...  0.795016  0.003878  0.623521  0.598782   \n",
       "\n",
       "     feat_90   feat_91   feat_92   feat_93  feat_94   feat_95  \n",
       "id                                                             \n",
       "1   0.827890  0.290202  0.026601  0.564050        1  0.016469  \n",
       "2   0.839969  0.283846  0.264577  0.570175        1  0.020794  \n",
       "3   0.836774  0.290189  0.026555  0.563706        1  0.016474  \n",
       "4   0.834697  0.281721  0.026697  0.564663        1  0.023982  \n",
       "5   0.839973  0.278514  0.024752  0.575617        1  0.035490  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle(\"data/taiwan-bankruptcy-data.json.gz\")\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5db4c5-5320-4265-ac5c-0a817be7bb81",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbafe83-feef-45af-a68b-4bd315615740",
   "metadata": {},
   "source": [
    "I'll Create my feature matrix X and target vector y. my target is \"bankrupt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ca2251-c8ca-40a4-9891-d78a64d490d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (6137, 95)\n",
      "y shape: (6137,)\n"
     ]
    }
   ],
   "source": [
    "target = \"bankrupt\"\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10ed62-541f-463f-9d2b-a753de1128b5",
   "metadata": {},
   "source": [
    "Now i'll divide my data (X and y) into training and test sets using a randomized train-test split. my test set is 20% of my total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371e2b4f-08aa-473f-b9d7-f41b0f5cda63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4909, 95)\n",
      "y_train shape: (4909,)\n",
      "X_test shape: (1228, 95)\n",
      "y_test shape: (1228,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be462d81-1844-4623-918e-c8ff3654c650",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b35b0e-8d7a-4a22-a222-8204cf781c15",
   "metadata": {},
   "source": [
    "Remember the data is imbalanced so I need to resample. I am  going to use the over sampling method because from the previous task it yielded a better accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74ef1c6-74b7-4b49-88f3-354518d3fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_over shape: (9512, 95)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>feat_94</th>\n",
       "      <th>feat_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535855</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.594411</td>\n",
       "      <td>0.627099</td>\n",
       "      <td>0.627099</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>0.797686</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.303518</td>\n",
       "      <td>0.781865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834091</td>\n",
       "      <td>0.022025</td>\n",
       "      <td>0.624364</td>\n",
       "      <td>0.627101</td>\n",
       "      <td>0.841977</td>\n",
       "      <td>0.275384</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.554136</td>\n",
       "      <td>0.612734</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.607388</td>\n",
       "      <td>0.607388</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.797614</td>\n",
       "      <td>0.809483</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.781754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840293</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.624548</td>\n",
       "      <td>0.607385</td>\n",
       "      <td>0.842645</td>\n",
       "      <td>0.276532</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.549554</td>\n",
       "      <td>0.603467</td>\n",
       "      <td>0.599122</td>\n",
       "      <td>0.620166</td>\n",
       "      <td>0.620166</td>\n",
       "      <td>0.999119</td>\n",
       "      <td>0.797569</td>\n",
       "      <td>0.809470</td>\n",
       "      <td>0.303524</td>\n",
       "      <td>0.781740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840403</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.624010</td>\n",
       "      <td>0.620163</td>\n",
       "      <td>0.842873</td>\n",
       "      <td>0.277249</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.543801</td>\n",
       "      <td>0.603249</td>\n",
       "      <td>0.606992</td>\n",
       "      <td>0.622515</td>\n",
       "      <td>0.622515</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0.797728</td>\n",
       "      <td>0.809649</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>0.781930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>0.626775</td>\n",
       "      <td>0.622513</td>\n",
       "      <td>0.842989</td>\n",
       "      <td>0.280013</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.498659</td>\n",
       "      <td>0.562364</td>\n",
       "      <td>0.546978</td>\n",
       "      <td>0.603670</td>\n",
       "      <td>0.603670</td>\n",
       "      <td>0.998904</td>\n",
       "      <td>0.797584</td>\n",
       "      <td>0.809459</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.781713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811988</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.623674</td>\n",
       "      <td>0.603669</td>\n",
       "      <td>0.841105</td>\n",
       "      <td>0.277628</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>0.565618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
       "0  0.535855  0.599160  0.594411  0.627099  0.627099  0.999220  0.797686   \n",
       "1  0.554136  0.612734  0.595000  0.607388  0.607388  0.999120  0.797614   \n",
       "2  0.549554  0.603467  0.599122  0.620166  0.620166  0.999119  0.797569   \n",
       "3  0.543801  0.603249  0.606992  0.622515  0.622515  0.999259  0.797728   \n",
       "4  0.498659  0.562364  0.546978  0.603670  0.603670  0.998904  0.797584   \n",
       "\n",
       "     feat_8    feat_9   feat_10  ...   feat_86   feat_87   feat_88   feat_89  \\\n",
       "0  0.809591  0.303518  0.781865  ...  0.834091  0.022025  0.624364  0.627101   \n",
       "1  0.809483  0.303600  0.781754  ...  0.840293  0.002407  0.624548  0.607385   \n",
       "2  0.809470  0.303524  0.781740  ...  0.840403  0.000840  0.624010  0.620163   \n",
       "3  0.809649  0.303510  0.781930  ...  0.831514  0.006176  0.626775  0.622513   \n",
       "4  0.809459  0.304000  0.781713  ...  0.811988  0.004256  0.623674  0.603669   \n",
       "\n",
       "    feat_90   feat_91   feat_92   feat_93  feat_94   feat_95  \n",
       "0  0.841977  0.275384  0.026791  0.565158        1  0.147943  \n",
       "1  0.842645  0.276532  0.026791  0.565158        1  0.062544  \n",
       "2  0.842873  0.277249  0.026800  0.565200        1  0.047929  \n",
       "3  0.842989  0.280013  0.026839  0.565375        1  0.028386  \n",
       "4  0.841105  0.277628  0.026897  0.565618        1  0.043080  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train,y_train)\n",
    "print(\"X_train_over shape:\", X_train_over.shape)\n",
    "X_train_over.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f226676-3ec0-4752-a9dd-0a5e48323e43",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930924fe-cd63-4933-a3b8-9d2085dcb846",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d30111-d76e-4a0a-b1b0-6fe64c0aa642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "# Calculate the baseline accuracy score for my model.\n",
    "acc_baseline = y_train.value_counts(normalize=True).max()\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d24c38-d745-48bf-9cda-a2cbd0affdfc",
   "metadata": {},
   "source": [
    "## Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fef0d0-9e9e-45a7-8329-9605bcc05bd0",
   "metadata": {},
   "source": [
    "Ensemble models work by building multiple models on random subsets of the same data, and then comparing their predictions to make a final prediction. Since I used a random forest trees in the last project, we're going to be considering the gradient boosting tree here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd3ccd-08c2-4577-9eee-9393471bd16c",
   "metadata": {},
   "source": [
    "Now I'll Create a pipeline named clf (short for \"classifier\") that contains a GradientBoostingClassifier predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec6389e5-0fe7-429e-9a9f-555447fe0b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958eab6f-9034-4ab8-bd7b-928ca5b21a2b",
   "metadata": {},
   "source": [
    "Remember while Iwas doing this that I only want to be looking at the positive class. Here, the positive class is the one where the companies really did go bankrupt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70fb58-3aa9-4c60-b842-e14673aa2469",
   "metadata": {},
   "source": [
    "Next, I am going to tune some of the hyperparameters for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fce9445-9f0c-400d-ad74-8f9ebe225db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': range(20, 31, 5), 'max_depth': range(2, 5)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with the range of hyperparameters that we want to evaluate for our classifier\n",
    "params = {\n",
    "    \"n_estimators\": range(20,31,5),\n",
    "    \"max_depth\":  range(2,5)\n",
    "}\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef041a46-8727-4ed0-9e9a-0925a3f1c308",
   "metadata": {},
   "source": [
    "Note that I am trying much smaller numbers of n_estimators. This is because GradientBoostingClassifier is slower to train than the RandomForestClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b4d38-9485-4937-8db3-4b8a0e7600b1",
   "metadata": {},
   "source": [
    "Next I'll Create a GridSearchCV named model that includes my classifier and hyperparameter grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a70740-2693-462c-8651-e576d9dbace1",
   "metadata": {},
   "source": [
    "GridSearchCV takes as input a model, a grid of hyperparameter values to search over, a cross-validation strategy, and a performance metric to optimize for. It then trains and evaluates the model for each possible combination of hyperparameters in the grid, using cross-validation to estimate the performance of each combination. Finally, it returns the hyperparameters that achieved the highest performance according to the specified metric.\n",
    "\n",
    "Overall, GridSearchCV is a powerful tool for finding the best hyperparameters for a given machine learning model, and it can help to improve the accuracy and generalization of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433ff65f-796c-4bcd-bc82-d63235a0a1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(2, 5),\n",
       "                         &#x27;n_estimators&#x27;: range(20, 31, 5)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(2, 5),\n",
       "                         &#x27;n_estimators&#x27;: range(20, 31, 5)},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 5),\n",
       "                         'n_estimators': range(20, 31, 5)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    "\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21a044-7e5c-41cc-a4f0-bdd2e88ba5c2",
   "metadata": {},
   "source": [
    "Now that I have everything i need for the model, I'll fit it to the data and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84637060-0347-4137-a7b6-b64a38ac2006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(2, 5),\n",
       "                         &#x27;n_estimators&#x27;: range(20, 31, 5)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(2, 5),\n",
       "                         &#x27;n_estimators&#x27;: range(20, 31, 5)},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 5),\n",
       "                         'n_estimators': range(20, 31, 5)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model to over-sampled training data\n",
    "model.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4117984-0574-4aea-900f-f7652e4732ff",
   "metadata": {},
   "source": [
    "Next I'll Extract the cross-validation results from model and load them into a DataFrame named cv_results.\n",
    "\n",
    "Cross-validation is a technique used in machine learning to evaluate the performance of a model on unseen data. The basic idea is to split the available data into several subsets or folds, train the model on a portion of the data (the training set), and then test it on the remaining data (the validation set). This process is repeated multiple times, with different subsets of data used for training and validation each time. The results from each fold are then averaged to give an estimate of the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3509dd62-f731-49fd-915f-e882afe87394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.088136</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 20}</td>\n",
       "      <td>0.909616</td>\n",
       "      <td>0.897530</td>\n",
       "      <td>0.903260</td>\n",
       "      <td>0.905363</td>\n",
       "      <td>0.906414</td>\n",
       "      <td>0.904437</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.121241</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 25}</td>\n",
       "      <td>0.912769</td>\n",
       "      <td>0.913820</td>\n",
       "      <td>0.917455</td>\n",
       "      <td>0.913775</td>\n",
       "      <td>0.912198</td>\n",
       "      <td>0.914004</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.151623</td>\n",
       "      <td>0.041161</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 30}</td>\n",
       "      <td>0.923279</td>\n",
       "      <td>0.917499</td>\n",
       "      <td>0.916930</td>\n",
       "      <td>0.923239</td>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.920101</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.865593</td>\n",
       "      <td>0.044609</td>\n",
       "      <td>0.029694</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 20}</td>\n",
       "      <td>0.929585</td>\n",
       "      <td>0.930636</td>\n",
       "      <td>0.932177</td>\n",
       "      <td>0.934805</td>\n",
       "      <td>0.931651</td>\n",
       "      <td>0.931771</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.337993</td>\n",
       "      <td>0.044213</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 25}</td>\n",
       "      <td>0.935365</td>\n",
       "      <td>0.931687</td>\n",
       "      <td>0.939537</td>\n",
       "      <td>0.937434</td>\n",
       "      <td>0.935331</td>\n",
       "      <td>0.935871</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.840607</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.042153</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 30}</td>\n",
       "      <td>0.941146</td>\n",
       "      <td>0.940620</td>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>0.943743</td>\n",
       "      <td>0.942179</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.677375</td>\n",
       "      <td>0.115437</td>\n",
       "      <td>0.017132</td>\n",
       "      <td>0.024343</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 20}</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.955859</td>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.961094</td>\n",
       "      <td>0.955836</td>\n",
       "      <td>0.957948</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.545967</td>\n",
       "      <td>0.044977</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 25}</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.961114</td>\n",
       "      <td>0.957939</td>\n",
       "      <td>0.965825</td>\n",
       "      <td>0.962671</td>\n",
       "      <td>0.961417</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.674530</td>\n",
       "      <td>0.219133</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 30}</td>\n",
       "      <td>0.965318</td>\n",
       "      <td>0.963216</td>\n",
       "      <td>0.963197</td>\n",
       "      <td>0.967928</td>\n",
       "      <td>0.964248</td>\n",
       "      <td>0.964781</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.088136      0.007476         0.004577        0.000189   \n",
       "1       5.121241      0.038522         0.004798        0.000312   \n",
       "2       6.151623      0.041161         0.004723        0.000178   \n",
       "3       5.865593      0.044609         0.029694        0.030563   \n",
       "4       7.337993      0.044213         0.004765        0.000160   \n",
       "5       8.840607      0.068041         0.042153        0.030436   \n",
       "6       7.677375      0.115437         0.017132        0.024343   \n",
       "7       9.545967      0.044977         0.017779        0.025921   \n",
       "8      11.674530      0.219133         0.005378        0.000724   \n",
       "\n",
       "  param_max_depth param_n_estimators                                params  \\\n",
       "0               2                 20  {'max_depth': 2, 'n_estimators': 20}   \n",
       "1               2                 25  {'max_depth': 2, 'n_estimators': 25}   \n",
       "2               2                 30  {'max_depth': 2, 'n_estimators': 30}   \n",
       "3               3                 20  {'max_depth': 3, 'n_estimators': 20}   \n",
       "4               3                 25  {'max_depth': 3, 'n_estimators': 25}   \n",
       "5               3                 30  {'max_depth': 3, 'n_estimators': 30}   \n",
       "6               4                 20  {'max_depth': 4, 'n_estimators': 20}   \n",
       "7               4                 25  {'max_depth': 4, 'n_estimators': 25}   \n",
       "8               4                 30  {'max_depth': 4, 'n_estimators': 30}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.909616           0.897530           0.903260           0.905363   \n",
       "1           0.912769           0.913820           0.917455           0.913775   \n",
       "2           0.923279           0.917499           0.916930           0.923239   \n",
       "3           0.929585           0.930636           0.932177           0.934805   \n",
       "4           0.935365           0.931687           0.939537           0.937434   \n",
       "5           0.941146           0.940620           0.943218           0.942166   \n",
       "6           0.959538           0.955859           0.957413           0.961094   \n",
       "7           0.959538           0.961114           0.957939           0.965825   \n",
       "8           0.965318           0.963216           0.963197           0.967928   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.906414         0.904437        0.004017                9  \n",
       "1           0.912198         0.914004        0.001832                8  \n",
       "2           0.919558         0.920101        0.002723                7  \n",
       "3           0.931651         0.931771        0.001758                6  \n",
       "4           0.935331         0.935871        0.002605                5  \n",
       "5           0.943743         0.942179        0.001185                4  \n",
       "6           0.955836         0.957948        0.002075                3  \n",
       "7           0.962671         0.961417        0.002710                2  \n",
       "8           0.964248         0.964781        0.001757                1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(model.cv_results_)\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d01826-dc64-4e1d-8de0-689ca2017662",
   "metadata": {},
   "source": [
    "Next, I'll look at the hyperparameters that led to the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b62dde2-6b59-4ae3-948c-81e7a5287eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the best model paramters is : {'max_depth': 4, 'n_estimators': 30}\n",
      " the model best score is : 0.9647814370248315\n"
     ]
    }
   ],
   "source": [
    "# Extract best hyperparameters\n",
    "best_model_par = model.best_params_\n",
    "model_best_score = model.best_score_\n",
    "\n",
    "print(f\" the best model paramters is : {best_model_par}\")\n",
    "print(f\" the model best score is : {model_best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c43d5b-9e33-46ca-bc78-304ca4a0552e",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b2308-ea0a-49c1-bb4c-a36c0161b403",
   "metadata": {},
   "source": [
    "Now that I have a working model that's actually giving us something useful, I'll  like to see  how good it really is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b2e3567-90ad-4da3-a91d-155e6082cb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9466\n",
      "Validation Accuracy: 0.9389\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score for my model \n",
    "acc_train =  model.score(X_train,y_train)\n",
    "acc_test = model.score(X_test,y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", round(acc_train, 4))\n",
    "print(\"Validation Accuracy:\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063db74-63ff-40dc-9e2f-7804f9fa1bd5",
   "metadata": {},
   "source": [
    "Just like before, I'll create a confusion matrix to see how my model is making its correct and incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f0fee4-13b3-43cf-be71-4f8013f40553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(model,X_test,y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c6cdc-ae90-45b9-8d04-ac567aac32e4",
   "metadata": {},
   "source": [
    "This matrix is a great reminder of how imbalanced my data is, and of why accuracy isn't always the best metric for judging whether or not a model is giving us what we want. After all, if 95% of the companies in our dataset didn't go bankrupt, all the model has to do is always predict {\"bankrupt\": False}, and it'll be right 95% of the time. The accuracy score will be amazing, but it won't tell us what we really need to know.\n",
    "\n",
    "Instead, I can evaluate our model using two new metrics: precision and recall. The precision score is important when my model is to only predict that a company will go bankrupt if its very confident in its prediction. The recall score is important if I want to make sure to identify all the companies that will go bankrupt, even if that means being incorrect sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dcdb39-aabe-4127-b8fe-77072af9a805",
   "metadata": {},
   "source": [
    "Next I'll Print the classification report for my model, using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3efbd078-1fcd-47eb-a230-11268697d755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.94      0.97      1191\n",
      "        True       0.31      0.81      0.44        37\n",
      "\n",
      "    accuracy                           0.94      1228\n",
      "   macro avg       0.65      0.88      0.71      1228\n",
      "weighted avg       0.97      0.94      0.95      1228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373f52d-51f1-4d17-a9ac-7c71c57db5e0",
   "metadata": {},
   "source": [
    "Precision and recall are two common metrics used in machine learning to evaluate the performance of a binary classification model.\n",
    "\n",
    "Precision is the fraction of true positive predictions (correctly predicted positive examples) among all positive predictions made by the model. In other words, it measures how accurate the model is when it predicts positive examples. A high precision indicates that the model is making few false positive predictions.\n",
    "\n",
    "Recall, on the other hand, is the fraction of true positive predictions among all actual positive examples in the dataset. It measures how well the model can identify positive examples, regardless of how many false positives it may predict. A high recall indicates that the model is identifying a large proportion of the positive examples in the dataset.\n",
    "\n",
    "In general, precision and recall are inversely related: increasing precision typically decreases recall and vice versa. A good balance between precision and recall is often desired, depending on the specific problem and application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647a0a8-a81e-4f56-a6d0-74d029d55ab3",
   "metadata": {},
   "source": [
    "I'll create a confusion matrix containing precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64df5122-87be-4183-8783-17d61a027866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d23bf018db4740a874fca2e647e2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, continuous_update=False, description='Threshold:', max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e68bf09bf7549b29d241660837bd2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(height='300px', width='300px')), VBox(children=(Output(layout=Layout(heigh…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ConfusionMatrixWidget(model, X_test, y_test)\n",
    "c.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd0b7b-2ef3-42c0-ac6c-2e3b4b586fb1",
   "metadata": {},
   "source": [
    "Next I'll Create an interactive dashboard that shows how company profit and losses change in relationship to my model's probability threshold.I'll Start with the make_cnf_matrix function, which should calculate and print profit/losses, and display a confusion matrix. Then I'll create a FloatSlider thresh_widget that ranges from 0 to 1. Finally combine my function and slider in the interact function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71cfdb90-3980-43b9-bda6-53bd35d862a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8be5241c0cc40dca010a989ee669642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='threshold', max=1.0, step=0.05), Output()), _dom_cla…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_cnf_matrix(threshold):\n",
    "    y_pred_proba = model.predict_proba(X_test)[:,-1]\n",
    "    y_pred = y_pred_proba > threshold\n",
    "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    tn,fp,fn,tp = conf_matrix.ravel()\n",
    "    print(f\"Profit:€{tp * 100_000_000}\" )\n",
    "    print(f\"Losses:€{tp * 250_000_000}\" )\n",
    "    print(f\"Sum:€{(tp * 100_000_000)+(tp * 250_000_000)}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test,y_pred,colorbar=False)\n",
    "\n",
    "\n",
    "thresh_widget = widgets.FloatSlider(min=0,max=1,value=0.5,step=0.05)\n",
    "\n",
    "interact(make_cnf_matrix, threshold=thresh_widget);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a087b-9229-4d5e-bc87-26c539d5ac7f",
   "metadata": {},
   "source": [
    "# Communicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606ed4e-0df3-4358-8dcc-cd1927a3d56e",
   "metadata": {},
   "source": [
    "Now I'll Create a bar chart with the 15 most important features for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0a534a0-d466-4534-aeef-16b32aa002a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature names from training data\n",
    "features = X_train_over.columns\n",
    "# Extract importances from model\n",
    "importances = importances = model.best_estimator_.feature_importances_\n",
    "# Create a series with feature names and importances\n",
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "# Plot 10 most important features\n",
    "feat_imp.tail(10).plot(kind=\"bar\",color =\"g\")\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b1551-c69c-4790-916d-c31607f24f0c",
   "metadata": {},
   "source": [
    "Finally Using a context manager, I'll save my best-performing model to a a file named \"model-Gradient-Boosting-Trees.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f730371-2f66-41f0-8762-21a7efd9f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model as `\"model-random-forest.pkl\"`\n",
    "with open(\"model-Gradient-Boosting-Trees.pkl\",\"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
